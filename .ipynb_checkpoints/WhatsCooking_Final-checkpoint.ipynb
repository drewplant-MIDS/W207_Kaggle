{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json  # For importing json files\n",
    "import numpy as np\n",
    "import re # For regular expression filtering of categories\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  # If we wanted to use TfIdf...probably not necessary though\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open up a file-handle for the text json file train_data.json\n",
    "trainfh = open('train.json')\n",
    "train_list = json.load(fp=trainfh)\n",
    "testfh = open('test.json')\n",
    "test_list = json.load(fp=testfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [u'plain flour', u'ground pepper', u'salt', u'tomatoes', u'ground black pepper', u'thyme', u'eggs', u'green tomatoes', u'yellow corn meal', u'milk', u'vegetable oil']\n",
      " [u'eggs', u'pepper', u'salt', u'mayonaise', u'cooking oil', u'green chilies', u'grilled chicken breasts', u'garlic powder', u'yellow onion', u'soy sauce', u'butter', u'chicken livers']]\n",
      "Number of training records: 39774\n",
      "Training data keys:  [u'cuisine', u'id', u'ingredients']\n",
      "Number of distinct cuisines is 20\n",
      "(33000,)\n",
      "ParsleySprig Radish SeaSalt Pozole ChickenStock WhiteOnion Tomatillo GarlicClove CanolaOil BonelessPorkShoulder Pork ShreddedCabbage RomaineLettuceLeaf DriedOregano SerranoChilies Lime Epazote GreenPumpkinSeed\n",
      "mexican\n"
     ]
    }
   ],
   "source": [
    "# Extract the training features (ingredients) for each id\n",
    "XIngredients=np.asarray([train_row['ingredients'] for train_row in train_list])\n",
    "print XIngredients[1:3]\n",
    "print \"Number of training records: %d\"  %(XIngredients.shape)\n",
    "# Note that 3 dictionaries are Extracted per line:  'cuisine', 'id', and 'ingredients'\n",
    "print 'Training data keys:  %s' %train_list[0].keys()\n",
    "# Extract training labels (type of cuisine) for each id\n",
    "YCuisine=np.asarray([train_row['cuisine'] for train_row in train_list])\n",
    "# Extract unique Cuisine categories from the train_list \n",
    "CuisineSet = set()\n",
    "for i in range(YCuisine.shape[0]):\n",
    "    CuisineSet.add(YCuisine[i])\n",
    "# Transform CuisineCategories to a dictionary to convert cuisine labels to numeric values\n",
    "CuisineList = [Cuisine for Cuisine in CuisineSet]\n",
    "CuisineDict = {CuisineList[i]:i for i in range(len(CuisineList))}\n",
    "num_classes = len(CuisineDict.keys())\n",
    "print \"Number of distinct cuisines is %d\" %len(CuisineDict.keys())\n",
    "\n",
    "\n",
    "# Shuffle training data and labels; \n",
    "shuffle = np.random.permutation(np.arange(XIngredients.shape[0]))\n",
    "XIngredients, YCuisine = XIngredients[shuffle], YCuisine[shuffle]\n",
    "# Convert YCuisine (text list) to numeric values based on CuisineDict\n",
    "YNum = [CuisineDict[Key] for Key in YCuisine]\n",
    "\n",
    "# Function to decide if a word is plural or not\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def isplural(word):\n",
    "    lemma = wnl.lemmatize(word, 'n')\n",
    "    plural = True if word is not lemma else False\n",
    "    return plural, lemma\n",
    "\n",
    "adjs = ['cooking', 'large', 'cracked']\n",
    "\n",
    "# Function to convert records of lists of lower-case ingredient elements into records of space-separated CamelCase ingredients\n",
    "def CamelizeRecords(Records):\n",
    "    NewX = [] # New record array\n",
    "    for IngredientList in Records:\n",
    "        IngredientCamelList=[] # Will store CamelCase list of ingredients for this record\n",
    "        for Element in IngredientList: # Element is a single string possibly multi-word ingredient within this record\n",
    "            WordList = []\n",
    "            for Word in Element.split():\n",
    "                Word = Word.capitalize()\n",
    "                WordList.append(Word)\n",
    "            # Finally, collapse all words in ElementList\n",
    "            CamelWord = ''.join(WordList) # join Element words into single CamelCase word\n",
    "            IngredientCamelList.append(CamelWord) # Add CamelWord to this record ingredient list\n",
    "        NewX.append(' '.join(IngredientCamelList)) # Append single text field of CamelCase ingredients as new record\n",
    "    return np.asarray(NewX)\n",
    "\n",
    "\n",
    "# Function to convert records of lists of lower-case ingredient elements into records of space-separated CamelCase ingredients\n",
    "def CamelizeRecords2(Records):\n",
    "    NewX = [] # New record array\n",
    "    for IngredientList in Records:\n",
    "        IngredientCamelList=[] # Will store CamelCase list of ingredients for this record\n",
    "        for Element in IngredientList: # Element is a single string possibly multi-word ingredient within this record\n",
    "            WordList = []\n",
    "            for Word in Element.split():\n",
    "            \n",
    "                # Change pluaral to singular\n",
    "                Word = isplural(Word)[1]  \n",
    "                    \n",
    "                for adj in adjs:\n",
    "                    if Word.lower() == adj:\n",
    "                        Word = ''\n",
    "                \n",
    "                Word = Word.capitalize()                \n",
    "                WordList.append(Word)\n",
    "\n",
    "            # Finally, collapse all words in ElementList\n",
    "            CamelWord = ''.join(WordList) # join Element words into single CamelCase word\n",
    "            IngredientCamelList.append(CamelWord) # Add CamelWord to this record ingredient list\n",
    "        NewX.append(' '.join(IngredientCamelList)) # Append single text field of CamelCase ingredients as new record\n",
    "    return np.asarray(NewX)\n",
    "\n",
    "# Here's another idea -- split multi-word feature into multiple single-word features\n",
    "def Fission(Records):\n",
    "    Limit = 5 # Limit the accepted length of words\n",
    "    newX = [] # New record array\n",
    "    for IngredientList in Records:\n",
    "        IngredientFissionList = []\n",
    "        for Element in IngredientList:\n",
    "            for Word in Element.split():\n",
    "                Word = Word.lower()\n",
    "                # Only include words which are not digits\n",
    "                #if re.match(r'jeru',Word.lower()):\n",
    "                 #   print Word\n",
    "                if not (re.match(r'^[\\d\\%]+$',Word) or re.match(r'.+ed$',Word)):\n",
    "                    if len(Word) > Limit:\n",
    "                        Word = Word[0:Limit]\n",
    "                    IngredientFissionList.append(Word)\n",
    "        newX.append(' '.join(IngredientFissionList))\n",
    "    return np.asarray(newX)\n",
    "\n",
    "\n",
    "# Reformat training data into CamelCase\n",
    "TrainX = CamelizeRecords2(XIngredients)\n",
    "\n",
    "# Separate out training data/labels into 33000 training and 6774 \"hold-out\" dev data/labels\n",
    "train_data, train_classes = TrainX[:33000], YNum[:33000]\n",
    "dev_data, dev_classes = TrainX[33001:], YNum[33001:]\n",
    "print train_data.shape\n",
    "print train_data[1]\n",
    "print CuisineList[YNum[1]]\n",
    " \n",
    "# Now try out Fission() for producing lower-feature number\n",
    "TrainXFission = Fission(XIngredients)\n",
    "# Once again Separate out training data/labels into 33000 training and 6774 \"hold-out\" dev data/labels\n",
    "train_data2 = TrainXFission[:33000]\n",
    "dev_data2 = TrainXFission[33001:]    \n",
    "    \n",
    "\n",
    "# Create features, labels for test_data\n",
    "XTestIngredients = np.asarray([test_row['ingredients'] for test_row in test_list])\n",
    "#print \"Number of test records: %d\" %XTestIngredients.shape\n",
    "# Note that test data has no 'cuisine' (no labels...)\n",
    "#print  'Test data keys:  %s' %test_list[0].keys()\n",
    "# Convert test data to CamelCase text strings as was done for training data above\n",
    "test_data = CamelizeRecords(XTestIngredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes shows a prediction accuracy of 0.721837\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default - With CamelCasing\n",
    "CountVec = CountVectorizer()\n",
    "FitTransformTrain = CountVec.fit_transform(train_data)\n",
    "# Try Multinomial Naive Bayes first\n",
    "ClfMNB = MultinomialNB().fit(FitTransformTrain,train_classes)\n",
    "# Predict Cuisine in the dev data set\n",
    "#   Transform the dev data using the feature extractor from the train_data\n",
    "TransformedDev = CountVec.transform(dev_data)\n",
    "predicted = ClfMNB.predict(TransformedDev)\n",
    "# Calculate accuracy of predictions on dev data\n",
    "print \"Multinomial Naive Bayes shows a prediction accuracy of %f\" %(np.mean(predicted == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 0.001  prediction accuracy of 0.727300\n",
      "With alpha = 0.01  prediction accuracy of 0.738521\n",
      "With alpha = 1  prediction accuracy of 0.721837\n",
      "With alpha = 2  prediction accuracy of 0.689798\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes- Different alpha - With CamelCasing\n",
    "alpha = [.001,.01,1,2]\n",
    "for a in alpha:\n",
    "    ClfMNBalpha = MultinomialNB(alpha=a).fit(FitTransformTrain,train_classes)\n",
    "    # Predict Cuisine in the dev data set\n",
    "    # Transform the dev data using the feature extractor from the train_data\n",
    "    predictedalpha = ClfMNBalpha.predict(TransformedDev)\n",
    "\n",
    "    print 'With alpha =',a,' prediction accuracy of %f' %(np.mean(predictedalpha == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest score is 0.741030562528\n",
      "using max_df of 0.1\n"
     ]
    }
   ],
   "source": [
    "# Trying Different ,max_df\n",
    "max_dfs = [.05,.07,.1,.2,.25,.3,.35,.4]\n",
    "maxDF=0\n",
    "highest_score=0\n",
    "for i in max_dfs:\n",
    "    CountVec = CountVectorizer(max_df=i)\n",
    "    FitTransformTrain = CountVec.fit_transform(train_data)\n",
    "    #print 'with max_df = ', i,' the number of word in vocab is ',FitTransformTrain.shape[1]\n",
    "    # Try Multinomial Naive Bayes first\n",
    "    ClfMNB = MultinomialNB(alpha=.01).fit(FitTransformTrain,train_classes,)\n",
    "    # Predict Cuisine in the dev data set\n",
    "    #   Transform the dev data using the feature extractor from the train_data\n",
    "    TransformedDev = CountVec.transform(dev_data)\n",
    "    predicted = ClfMNB.predict(TransformedDev)\n",
    "    # Calculate accuracy of predictions on dev data\n",
    "    #print \"Multinomial Naive Bayes shows a prediction accuracy of %f\" %(np.mean(predicted == dev_classes))\n",
    "    if (np.mean(predicted == dev_classes))>highest_score:\n",
    "        maxDF=i\n",
    "        highest_score=(np.mean(predicted == dev_classes))\n",
    "print 'highest score is',highest_score\n",
    "print 'using max_df of', maxDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with prior norm =  100 is 0.732467148974\n",
      "Multinomial Naive Bayes with prior norm =  1000 is 0.738077661302\n",
      "Multinomial Naive Bayes with prior norm =  1500 is 0.739111176731\n",
      "Multinomial Naive Bayes with prior norm =  2000 is 0.737634726118\n",
      "Multinomial Naive Bayes with prior norm =  2500 is 0.737044145873\n",
      "Multinomial Naive Bayes with prior norm =  3000 is 0.737044145873\n",
      "highest score is 0.73896353167\n",
      "max Norm is 100\n"
     ]
    }
   ],
   "source": [
    "#Changing the priors. - Naive Bayes with CamelCase\n",
    "CountVec = CountVectorizer(max_df=maxDF)\n",
    "FitTransformTrain = CountVec.fit_transform(train_data)\n",
    "TransformedDev = CountVec.transform(dev_data)\n",
    "\n",
    "#Trying different normalization factors. The larger the factor is, the closer the priors get to to flat distribution\n",
    "norm_factor= [100,1000,1500,2000,2500,3000]\n",
    "maxNorm=0\n",
    "highest_score=0\n",
    "for norm in norm_factor:\n",
    "    class_priors= (ClfMNB.class_count_+norm)/sum(ClfMNB.class_count_+norm)\n",
    "    ClfMNB_prior = MultinomialNB( class_prior = class_priors).fit(FitTransformTrain,train_classes)\n",
    "    predicted_prior = ClfMNB_prior.predict(TransformedDev)\n",
    "    print 'Multinomial Naive Bayes with prior norm = ', norm,'is', (np.mean(predicted_prior == dev_classes))\n",
    "    if (np.mean(predicted == dev_classes))>highest_score:\n",
    "        maxNorm=norm\n",
    "        highest_score=(np.mean(predicted == dev_classes))\n",
    "print 'highest score is',highest_score\n",
    "print 'max Norm is',maxNorm\n",
    "class_priors = (ClfMNB.class_count_+maxNorm)/sum(ClfMNB.class_count_+maxNorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with tf-idf shows a prediction accuracy of 0.742950\n"
     ]
    }
   ],
   "source": [
    "#trying TfidVectorizer\n",
    "CountVecT = TfidfVectorizer(max_df=maxDF)\n",
    "FitTransformTrainT = CountVecT.fit_transform(train_data)\n",
    "ClfMNBT = MultinomialNB(alpha=.01).fit(FitTransformTrainT,train_classes)\n",
    "# Predict Cuisine in the dev data set\n",
    "# Transform the dev data using the feature extractor from the train_data\n",
    "TransformedDevT = CountVecT.transform(dev_data)\n",
    "predictedT = ClfMNBT.predict(TransformedDevT)\n",
    "# Calculate accuracy of predictions on dev data\n",
    "print \"Multinomial Naive Bayes with tf-idf shows a prediction accuracy of %f\" %(np.mean(predictedT == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression shows a prediction accuracy of 0.754762\n",
      "Logistic Regression on training data shows a prediction accuracy of 0.799424\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with L2 \n",
    "LR = LogisticRegression()\n",
    "LR.fit(FitTransformTrainT,train_classes)\n",
    "predictedLR = LR.predict(TransformedDevT)\n",
    "predictedLR_Train = LR.predict(FitTransformTrain)\n",
    "print \"Logistic Regression shows a prediction accuracy of %f\" %(np.mean(predictedLR == dev_classes))\n",
    "print \"Logistic Regression on training data shows a prediction accuracy of %f\" %(np.mean(predictedLR_Train == train_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with l1 shows a prediction accuracy of 0.755795\n"
     ]
    }
   ],
   "source": [
    "#trying l1 - \n",
    "LR = LogisticRegression(penalty='l1')\n",
    "LR.fit(FitTransformTrainT,train_classes)\n",
    "predictedLR = LR.predict(TransformedDevT)\n",
    "\n",
    "print \"Logistic Regression with l1 shows a prediction accuracy of %f\" %(np.mean(predictedLR == dev_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 1.0\n",
      "Logistic Regression shows a prediction accuracy of 0.755795\n",
      "c = 2.0\n",
      "Logistic Regression shows a prediction accuracy of 0.768935\n",
      "c ="
     ]
    }
   ],
   "source": [
    "Cvalues=[1.0,2.0,3.0,4.0,5.0,6.0]\n",
    "for c in Cvalues:\n",
    "    LR = LogisticRegression(penalty='l1',C=c)\n",
    "    LR.fit(FitTransformTrainT,train_classes)\n",
    "    predictedLR = LR.predict(TransformedDevT)\n",
    "    print 'c =',c\n",
    "    print \"Logistic Regression shows a prediction accuracy of %f\" %(np.mean(predictedLR == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solvers=(\"newton-cg\", \"lbfgs\")\n",
    "for s in solvers:\n",
    "    LR = LogisticRegression(penalty='l1',C=4.0,solver=s,multi_class='multinomial')\n",
    "    LR.fit(FitTransformTrainT,train_classes)\n",
    "    predictedLR = LR.predict(TransformedDevT)\n",
    "    print 's=',s\n",
    "    print \"Logistic Regression with solver =\",s,\"shows a prediction accuracy of %f\" %(np.mean(predictedLR == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trying SVM\n",
    "sv=SVC()\n",
    "sv.fit(FitTransformTrainT,train_classes)\n",
    "predictedSV=sv.predict(TransformedDevT)\n",
    "print \"SVM shows a prediction accuracy of %f\" %(np.mean(predictedSV == dev_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How well does this model actualy predict the training data?\n",
    "predictedTrain= LR.predict(FitTransformTrainT)\n",
    "print classification_report(dev_classes,predictedLR)\n",
    "print classification_report(train_classes,predictedTrain)\n",
    "# the acuracy is capped at 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#top 4 ingredients\n",
    "coef= LR.coef_\n",
    "print coef.shape\n",
    "for i,line in enumerate (coef):\n",
    "    #for j,word in enumerate (line):\n",
    "        #print 'for word ',CountVec.get_feature_names()[j] ,' the coef is ', word\n",
    "    print 'for cuisine: ',CuisineList[i]\n",
    "    topI = np.argsort(line)[-4:]\n",
    "    for word in topI:\n",
    "        print CountVecT.get_feature_names()[word] \n",
    "        #print coef[i,word]\n",
    "    print '--------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variance of coeficient LR\n",
    "LR = LogisticRegression(penalty='l1',C=4.0)\n",
    "LR.fit(FitTransformTrainT,train_classes)\n",
    "coefLR=LR.coef_\n",
    "print coefLR.shape\n",
    "NumWords = 10;\n",
    "count=0\n",
    "varsLR  = np.zeros(coefLR.shape[1])\n",
    "for i in range(coefLR.shape[1]):\n",
    "    varsLR[i]= np.var(coefLR[:,i])\n",
    "    if np.var(coefLR[:,i]==0): count+=1\n",
    "LowVarLR= np.argsort(varsLR)[1:NumWords+1]\n",
    "HighVarLR=np.argsort(varsLR)[-NumWords:]\n",
    "\n",
    "#plt.hist (varsLR,20)\n",
    "#plt.show()\n",
    "for word in LowVarLR:\n",
    "    print CountVec.get_feature_names()[word] \n",
    "print'------------'\n",
    "for word in HighVarLR:\n",
    "    print CountVec.get_feature_names()[word] \n",
    "\n",
    "print '------------'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_prob = LR.predict_proba(TransformedDevT)\n",
    "threshold = .5\n",
    "error_counter_above=0\n",
    "error_counter=0\n",
    "counter=0\n",
    "counter_above=0\n",
    "for i,label in enumerate(dev_classes):\n",
    "    counter+=1\n",
    "    if np.sort(predicted_prob[i])[-1:]>threshold:\n",
    "        counter_above+=1\n",
    "    if label!=predictedLR[i]:\n",
    "        error_counter+=1\n",
    "        ##print 'projected: ',predictedLR[i], ' actual:', label\n",
    "        ##print np.argsort(predicted_prob[i])[-4:]\n",
    "        ##print np.sort(predicted_prob[i])[-4:]\n",
    "        if np.sort(predicted_prob[i])[-1:]>threshold:\n",
    "            error_counter_above+=1\n",
    "print 'selecting a threshold of ',threshold,' will select ', error_counter-error_counter_above,' errors out of',error_counter\n",
    "print 'selecting a threshold of ',threshold,' will select ', counter-counter_above-(error_counter-error_counter_above),' accurate out of',counter-error_counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#secondary analysis\n",
    "predictedLR2=np.zeros(predictedLR.shape)\n",
    "for i,label in enumerate(predictedLR):\n",
    "    if np.sort(predicted_prob[i])[-1:]<threshold: #we only want to look at datadata with a score below a certain threshold to \n",
    "        top4C = np.argsort(predicted_prob[i])[-4:] #select the classes which got the top 4 probabilities\n",
    "        #the indices for the training data which indicate training example with any of the 4 classes\n",
    "        indices = np.asarray(np.where((train_classes==top4C[0]) | (train_classes==top4C[1]) | (train_classes==top4C[2]) | (train_classes==top4C[3])))\n",
    "        train_data2=[]\n",
    "        train_classes2=[]\n",
    "        #new training data set and new training label set\n",
    "        for j,index in enumerate (indices[0,:]):\n",
    "            train_data2.append(train_data[index])\n",
    "            train_classes2.append(train_classes[index])\n",
    "        #new vectorizer, and LR classifier\n",
    "        CountVec2 = CountVectorizer(max_df=.1) #new vectorizer\n",
    "        FitTransform = CountVec2.fit_transform(train_data2)\n",
    "        LR2 = LogisticRegression().fit(FitTransform,train_classes2)\n",
    "        TransformedDev2 = CountVec2.transform(dev_data)\n",
    "        #new prediction\n",
    "        predicted2 = LR2.predict(TransformedDev2)\n",
    "        #add the new prediction to the main predicition list \n",
    "        predictedLR2[i]= predicted2[i]\n",
    "    else:predictedLR2[i]=predictedLR[i] #if above thrshold use the existing predicted class\n",
    "print \"Logistic Regression with added stage shows a prediction accuracy of %f\" %(np.mean(predictedLR2 == dev_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
