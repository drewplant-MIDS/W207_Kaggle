{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json  # For importing json files\n",
    "import numpy as np\n",
    "import re # For regular expression filtering of categories\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  # If we wanted to use TfIdf...probably not necessary though\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open up a file-handle for the text json file train_data.json\n",
    "trainfh = open('train.json')\n",
    "train_list = json.load(fp=trainfh)\n",
    "testfh = open('test.json')\n",
    "test_list = json.load(fp=testfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'cuisine': u'southern_us', u'id': 25693, u'ingredients': [u'plain flour', u'ground pepper', u'salt', u'tomatoes', u'ground black pepper', u'thyme', u'eggs', u'green tomatoes', u'yellow corn meal', u'milk', u'vegetable oil']}, {u'cuisine': u'filipino', u'id': 20130, u'ingredients': [u'eggs', u'pepper', u'salt', u'mayonaise', u'cooking oil', u'green chilies', u'grilled chicken breasts', u'garlic powder', u'yellow onion', u'soy sauce', u'butter', u'chicken livers']}, {u'cuisine': u'indian', u'id': 22213, u'ingredients': [u'water', u'vegetable oil', u'wheat', u'salt']}, {u'cuisine': u'indian', u'id': 13162, u'ingredients': [u'black pepper', u'shallots', u'cornflour', u'cayenne pepper', u'onions', u'garlic paste', u'milk', u'butter', u'salt', u'lemon juice', u'water', u'chili powder', u'passata', u'oil', u'ground cumin', u'boneless chicken skinless thigh', u'garam masala', u'double cream', u'natural yogurt', u'bay leaf']}]\n"
     ]
    }
   ],
   "source": [
    "print train_list[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [u'plain flour', u'ground pepper', u'salt', u'tomatoes', u'ground black pepper', u'thyme', u'eggs', u'green tomatoes', u'yellow corn meal', u'milk', u'vegetable oil']\n",
      " [u'eggs', u'pepper', u'salt', u'mayonaise', u'cooking oil', u'green chilies', u'grilled chicken breasts', u'garlic powder', u'yellow onion', u'soy sauce', u'butter', u'chicken livers']]\n",
      "Number of training records: 39774\n",
      "Training data keys:  [u'cuisine', u'id', u'ingredients']\n",
      "Number of distinct cuisines is 20\n"
     ]
    }
   ],
   "source": [
    "# Extract the training features (ingredients) for each id\n",
    "XIngredients=np.asarray([train_row['ingredients'] for train_row in train_list])\n",
    "print XIngredients[1:3]\n",
    "print \"Number of training records: %d\"  %(XIngredients.shape)\n",
    "# Note that 3 dictionaries are Extracted per line:  'cuisine', 'id', and 'ingredients'\n",
    "print 'Training data keys:  %s' %train_list[0].keys()\n",
    "# Extract training labels (type of cuisine) for each id\n",
    "YCuisine=np.asarray([train_row['cuisine'] for train_row in train_list])\n",
    "# Extract unique Cuisine categories from the train_list \n",
    "CuisineSet = set()\n",
    "for i in range(YCuisine.shape[0]):\n",
    "    CuisineSet.add(YCuisine[i])\n",
    "# Transform CuisineCategories to a dictionary to convert cuisine labels to numeric values\n",
    "CuisineList = [Cuisine for Cuisine in CuisineSet]\n",
    "CuisineDict = {CuisineList[i]:i for i in range(len(CuisineList))}\n",
    "num_classes = len(CuisineDict.keys())\n",
    "print \"Number of distinct cuisines is %d\" %len(CuisineDict.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle training data and labels; \n",
    "shuffle = np.random.permutation(np.arange(XIngredients.shape[0]))\n",
    "XIngredients, YCuisine = XIngredients[shuffle], YCuisine[shuffle]\n",
    "# Convert YCuisine (text list) to numeric values based on CuisineDict\n",
    "YNum = [CuisineDict[Key] for Key in YCuisine]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to decide if a word is plural or not\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "def isplural(word):\n",
    "    lemma = wnl.lemmatize(word, 'n')\n",
    "    plural = True if word is not lemma else False\n",
    "    return plural, lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, u'bean')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isplural(\"beans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adjs = ['plain', 'ground', 'cooking', 'fresh', 'large', 'crushed','shredded','roasted','cracked']\n",
    "adjs = ['large'] # do not exclude \"ground\",\"kosher\"\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert records of lists of lower-case ingredient elements into records of space-separated CamelCase ingredients\n",
    "def CamelizeRecords(Records):\n",
    "    NewX = [] # New record array\n",
    "    for IngredientList in Records:\n",
    "        IngredientCamelList=[] # Will store CamelCase list of ingredients for this record\n",
    "        for Element in IngredientList: # Element is a single string possibly multi-word ingredient within this record\n",
    "            WordList = []\n",
    "            for Word in Element.split():\n",
    "            \n",
    "                # Change pluaral to singular\n",
    "                Word = isplural(Word)[1]  \n",
    "                    \n",
    "                for adj in adjs:\n",
    "                    if Word.lower() == adj:\n",
    "                        Word = ''\n",
    "                \n",
    "                Word = Word.capitalize()                \n",
    "                WordList.append(Word)\n",
    "\n",
    "            # Finally, collapse all words in ElementList\n",
    "            CamelWord = ''.join(WordList) # join Element words into single CamelCase word\n",
    "            IngredientCamelList.append(CamelWord) # Add CamelWord to this record ingredient list\n",
    "        NewX.append(' '.join(IngredientCamelList)) # Append single text field of CamelCase ingredients as new record\n",
    "    return np.asarray(NewX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NavelOrange Egg Sugar WholeMilk\n",
      "french\n",
      "Number of test records: 9944\n",
      "Test data keys:  [u'id', u'ingredients']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reformat training data into CamelCase\n",
    "TrainX = CamelizeRecords(XIngredients)\n",
    "\n",
    "# Separate out training data/labels into 33000 training and 6774 \"hold-out\" dev data/labels\n",
    "train_data, train_classes = TrainX[:33000], YNum[:33000]\n",
    "\n",
    "dev_data, dev_classes = TrainX[33001:], YNum[33001:]\n",
    "\n",
    "print train_data[1]\n",
    "print CuisineList[YNum[1]]\n",
    " \n",
    "\n",
    "# Create features, labels for test_data\n",
    "XTestIngredients = np.asarray([test_row['ingredients'] for test_row in test_list])\n",
    "print \"Number of test records: %d\" %XTestIngredients.shape\n",
    "# Note that test data has no 'cuisine' (no labels...)\n",
    "print  'Test data keys:  %s' %test_list[0].keys()\n",
    "# Convert test data to CamelCase text strings as was done for training data above\n",
    "test_data = CamelizeRecords(XTestIngredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "witn max_df =  0.05  the number of word in vocab is  6408\n",
      "  (0, 3875)\t1\n",
      "  (0, 6256)\t1\n",
      "  (1, 3068)\t1\n",
      "  (1, 5427)\t1\n",
      "  (1, 528)\t1\n",
      "  (1, 1900)\t1\n",
      "  (1, 1615)\t1\n",
      "  (2, 2674)\t1\n",
      "  (2, 2306)\t1\n",
      "  (2, 2183)\t1\n",
      "  (2, 1476)\t1\n",
      "  (2, 6066)\t1\n",
      "  (2, 5107)\t1\n",
      "  (2, 4665)\t1\n",
      "  (2, 1043)\t1\n",
      "  (2, 5124)\t1\n",
      "  (2, 5036)\t1\n",
      "  (3, 2675)\t1\n",
      "  (3, 4671)\t1\n",
      "  (3, 4593)\t1\n",
      "  (3, 2720)\t1\n",
      "  (3, 1203)\t1\n",
      "  (3, 2159)\t1\n",
      "  (3, 1264)\t1\n",
      "  (3, 2318)\t1\n",
      "  :\t:\n",
      "  (5, 4752)\t1\n",
      "  (5, 4109)\t1\n",
      "  (5, 2698)\t1\n",
      "  (5, 2334)\t1\n",
      "  (6, 3408)\t1\n",
      "  (6, 1210)\t1\n",
      "  (6, 2556)\t1\n",
      "  (6, 1614)\t1\n",
      "  (6, 6127)\t1\n",
      "  (7, 2616)\t1\n",
      "  (7, 2761)\t1\n",
      "  (7, 5127)\t1\n",
      "  (7, 1998)\t1\n",
      "  (7, 1949)\t1\n",
      "  (7, 2812)\t2\n",
      "  (8, 4105)\t1\n",
      "  (8, 4544)\t1\n",
      "  (8, 3681)\t1\n",
      "  (8, 294)\t1\n",
      "  (8, 415)\t1\n",
      "  (8, 4802)\t1\n",
      "  (8, 1942)\t1\n",
      "  (8, 4394)\t1\n",
      "  (8, 2519)\t1\n",
      "  (8, 4459)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.737044\n",
      "witn max_df =  0.07  the number of word in vocab is  6415\n",
      "  (0, 3880)\t1\n",
      "  (0, 6263)\t1\n",
      "  (1, 3072)\t1\n",
      "  (1, 5432)\t1\n",
      "  (1, 1992)\t1\n",
      "  (1, 6127)\t1\n",
      "  (1, 529)\t1\n",
      "  (1, 1902)\t1\n",
      "  (1, 1617)\t1\n",
      "  (2, 2677)\t1\n",
      "  (2, 2309)\t1\n",
      "  (2, 2186)\t1\n",
      "  (2, 1478)\t1\n",
      "  (2, 6072)\t1\n",
      "  (2, 5112)\t1\n",
      "  (2, 4670)\t1\n",
      "  (2, 1044)\t1\n",
      "  (2, 5129)\t1\n",
      "  (2, 5041)\t1\n",
      "  (3, 1992)\t1\n",
      "  (3, 6127)\t1\n",
      "  (3, 2678)\t1\n",
      "  (3, 4676)\t1\n",
      "  (3, 4598)\t1\n",
      "  (3, 2723)\t1\n",
      "  :\t:\n",
      "  (5, 2701)\t1\n",
      "  (5, 2337)\t1\n",
      "  (6, 3412)\t1\n",
      "  (6, 1212)\t1\n",
      "  (6, 2559)\t1\n",
      "  (6, 1616)\t1\n",
      "  (6, 6134)\t1\n",
      "  (7, 2619)\t1\n",
      "  (7, 2765)\t1\n",
      "  (7, 5132)\t1\n",
      "  (7, 2001)\t1\n",
      "  (7, 3733)\t1\n",
      "  (7, 1951)\t1\n",
      "  (7, 2816)\t2\n",
      "  (8, 4110)\t1\n",
      "  (8, 4549)\t1\n",
      "  (8, 3685)\t1\n",
      "  (8, 294)\t1\n",
      "  (8, 415)\t1\n",
      "  (8, 2743)\t1\n",
      "  (8, 4807)\t1\n",
      "  (8, 1944)\t1\n",
      "  (8, 4399)\t1\n",
      "  (8, 2522)\t1\n",
      "  (8, 4464)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.738373\n",
      "witn max_df =  0.1  the number of word in vocab is  6420\n",
      "  (0, 3883)\t1\n",
      "  (0, 6268)\t1\n",
      "  (1, 3074)\t1\n",
      "  (1, 5436)\t1\n",
      "  (1, 1993)\t1\n",
      "  (1, 6132)\t1\n",
      "  (1, 529)\t1\n",
      "  (1, 1903)\t1\n",
      "  (1, 1618)\t1\n",
      "  (2, 5428)\t1\n",
      "  (2, 2678)\t1\n",
      "  (2, 2310)\t1\n",
      "  (2, 2187)\t1\n",
      "  (2, 1479)\t1\n",
      "  (2, 6077)\t1\n",
      "  (2, 5115)\t1\n",
      "  (2, 4673)\t1\n",
      "  (2, 1045)\t1\n",
      "  (2, 3253)\t1\n",
      "  (2, 5132)\t1\n",
      "  (2, 5044)\t1\n",
      "  (3, 1993)\t1\n",
      "  (3, 6132)\t1\n",
      "  (3, 2679)\t1\n",
      "  (3, 4679)\t1\n",
      "  :\t:\n",
      "  (5, 2338)\t1\n",
      "  (6, 3253)\t1\n",
      "  (6, 3415)\t1\n",
      "  (6, 1213)\t1\n",
      "  (6, 2560)\t1\n",
      "  (6, 1617)\t1\n",
      "  (6, 6139)\t1\n",
      "  (7, 2620)\t1\n",
      "  (7, 2767)\t1\n",
      "  (7, 5135)\t1\n",
      "  (7, 2002)\t1\n",
      "  (7, 3736)\t1\n",
      "  (7, 1952)\t1\n",
      "  (7, 2818)\t2\n",
      "  (8, 4113)\t1\n",
      "  (8, 4552)\t1\n",
      "  (8, 3688)\t1\n",
      "  (8, 294)\t1\n",
      "  (8, 415)\t1\n",
      "  (8, 2745)\t1\n",
      "  (8, 4810)\t1\n",
      "  (8, 1945)\t1\n",
      "  (8, 4402)\t1\n",
      "  (8, 2523)\t1\n",
      "  (8, 4467)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.738373\n",
      "witn max_df =  0.2  the number of word in vocab is  6431\n",
      "  (0, 5592)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 1942)\t1\n",
      "  (0, 6279)\t1\n",
      "  (1, 3080)\t1\n",
      "  (1, 5444)\t1\n",
      "  (1, 1996)\t1\n",
      "  (1, 6142)\t1\n",
      "  (1, 530)\t1\n",
      "  (1, 1905)\t1\n",
      "  (1, 1620)\t1\n",
      "  (2, 5592)\t1\n",
      "  (2, 5436)\t1\n",
      "  (2, 2735)\t1\n",
      "  (2, 2485)\t1\n",
      "  (2, 2683)\t1\n",
      "  (2, 2313)\t1\n",
      "  (2, 2190)\t1\n",
      "  (2, 1481)\t1\n",
      "  (2, 6086)\t1\n",
      "  (2, 5123)\t1\n",
      "  (2, 4681)\t1\n",
      "  (2, 1047)\t1\n",
      "  (2, 3259)\t1\n",
      "  (2, 5140)\t1\n",
      "  :\t:\n",
      "  (6, 6149)\t1\n",
      "  (7, 2735)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 4577)\t1\n",
      "  (7, 2625)\t1\n",
      "  (7, 2773)\t1\n",
      "  (7, 5143)\t1\n",
      "  (7, 2005)\t1\n",
      "  (7, 3742)\t1\n",
      "  (7, 730)\t1\n",
      "  (7, 1955)\t1\n",
      "  (7, 2824)\t2\n",
      "  (8, 5592)\t1\n",
      "  (8, 6161)\t1\n",
      "  (8, 4119)\t1\n",
      "  (8, 4559)\t1\n",
      "  (8, 3694)\t1\n",
      "  (8, 295)\t1\n",
      "  (8, 416)\t1\n",
      "  (8, 2751)\t1\n",
      "  (8, 4818)\t1\n",
      "  (8, 1948)\t1\n",
      "  (8, 4409)\t1\n",
      "  (8, 2528)\t1\n",
      "  (8, 4474)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.732615\n",
      "witn max_df =  0.25  the number of word in vocab is  6433\n",
      "  (0, 5594)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 1942)\t1\n",
      "  (0, 6281)\t1\n",
      "  (1, 3080)\t1\n",
      "  (1, 5446)\t1\n",
      "  (1, 1996)\t1\n",
      "  (1, 6144)\t1\n",
      "  (1, 530)\t1\n",
      "  (1, 1905)\t1\n",
      "  (1, 4007)\t1\n",
      "  (1, 1620)\t1\n",
      "  (2, 5594)\t1\n",
      "  (2, 4007)\t1\n",
      "  (2, 5438)\t1\n",
      "  (2, 2735)\t1\n",
      "  (2, 2485)\t1\n",
      "  (2, 2683)\t1\n",
      "  (2, 2313)\t1\n",
      "  (2, 2190)\t1\n",
      "  (2, 1481)\t1\n",
      "  (2, 6088)\t1\n",
      "  (2, 5125)\t1\n",
      "  (2, 4683)\t1\n",
      "  (2, 1047)\t1\n",
      "  :\t:\n",
      "  (6, 6151)\t1\n",
      "  (7, 2735)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 4579)\t1\n",
      "  (7, 2625)\t1\n",
      "  (7, 2773)\t1\n",
      "  (7, 5145)\t1\n",
      "  (7, 2005)\t1\n",
      "  (7, 3742)\t1\n",
      "  (7, 730)\t1\n",
      "  (7, 1955)\t1\n",
      "  (7, 2824)\t2\n",
      "  (8, 5594)\t1\n",
      "  (8, 6163)\t1\n",
      "  (8, 4121)\t1\n",
      "  (8, 4561)\t1\n",
      "  (8, 3694)\t1\n",
      "  (8, 295)\t1\n",
      "  (8, 416)\t1\n",
      "  (8, 2751)\t1\n",
      "  (8, 4820)\t1\n",
      "  (8, 1948)\t1\n",
      "  (8, 4411)\t1\n",
      "  (8, 2528)\t1\n",
      "  (8, 4476)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.732320\n",
      "witn max_df =  0.3  the number of word in vocab is  6433\n",
      "  (0, 5594)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 1942)\t1\n",
      "  (0, 6281)\t1\n",
      "  (1, 3080)\t1\n",
      "  (1, 5446)\t1\n",
      "  (1, 1996)\t1\n",
      "  (1, 6144)\t1\n",
      "  (1, 530)\t1\n",
      "  (1, 1905)\t1\n",
      "  (1, 4007)\t1\n",
      "  (1, 1620)\t1\n",
      "  (2, 5594)\t1\n",
      "  (2, 4007)\t1\n",
      "  (2, 5438)\t1\n",
      "  (2, 2735)\t1\n",
      "  (2, 2485)\t1\n",
      "  (2, 2683)\t1\n",
      "  (2, 2313)\t1\n",
      "  (2, 2190)\t1\n",
      "  (2, 1481)\t1\n",
      "  (2, 6088)\t1\n",
      "  (2, 5125)\t1\n",
      "  (2, 4683)\t1\n",
      "  (2, 1047)\t1\n",
      "  :\t:\n",
      "  (6, 6151)\t1\n",
      "  (7, 2735)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 4579)\t1\n",
      "  (7, 2625)\t1\n",
      "  (7, 2773)\t1\n",
      "  (7, 5145)\t1\n",
      "  (7, 2005)\t1\n",
      "  (7, 3742)\t1\n",
      "  (7, 730)\t1\n",
      "  (7, 1955)\t1\n",
      "  (7, 2824)\t2\n",
      "  (8, 5594)\t1\n",
      "  (8, 6163)\t1\n",
      "  (8, 4121)\t1\n",
      "  (8, 4561)\t1\n",
      "  (8, 3694)\t1\n",
      "  (8, 295)\t1\n",
      "  (8, 416)\t1\n",
      "  (8, 2751)\t1\n",
      "  (8, 4820)\t1\n",
      "  (8, 1948)\t1\n",
      "  (8, 4411)\t1\n",
      "  (8, 2528)\t1\n",
      "  (8, 4476)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.732320\n",
      "witn max_df =  0.35  the number of word in vocab is  6433\n",
      "  (0, 5594)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 1942)\t1\n",
      "  (0, 6281)\t1\n",
      "  (1, 3080)\t1\n",
      "  (1, 5446)\t1\n",
      "  (1, 1996)\t1\n",
      "  (1, 6144)\t1\n",
      "  (1, 530)\t1\n",
      "  (1, 1905)\t1\n",
      "  (1, 4007)\t1\n",
      "  (1, 1620)\t1\n",
      "  (2, 5594)\t1\n",
      "  (2, 4007)\t1\n",
      "  (2, 5438)\t1\n",
      "  (2, 2735)\t1\n",
      "  (2, 2485)\t1\n",
      "  (2, 2683)\t1\n",
      "  (2, 2313)\t1\n",
      "  (2, 2190)\t1\n",
      "  (2, 1481)\t1\n",
      "  (2, 6088)\t1\n",
      "  (2, 5125)\t1\n",
      "  (2, 4683)\t1\n",
      "  (2, 1047)\t1\n",
      "  :\t:\n",
      "  (6, 6151)\t1\n",
      "  (7, 2735)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 4579)\t1\n",
      "  (7, 2625)\t1\n",
      "  (7, 2773)\t1\n",
      "  (7, 5145)\t1\n",
      "  (7, 2005)\t1\n",
      "  (7, 3742)\t1\n",
      "  (7, 730)\t1\n",
      "  (7, 1955)\t1\n",
      "  (7, 2824)\t2\n",
      "  (8, 5594)\t1\n",
      "  (8, 6163)\t1\n",
      "  (8, 4121)\t1\n",
      "  (8, 4561)\t1\n",
      "  (8, 3694)\t1\n",
      "  (8, 295)\t1\n",
      "  (8, 416)\t1\n",
      "  (8, 2751)\t1\n",
      "  (8, 4820)\t1\n",
      "  (8, 1948)\t1\n",
      "  (8, 4411)\t1\n",
      "  (8, 2528)\t1\n",
      "  (8, 4476)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.732320\n",
      "witn max_df =  0.4  the number of word in vocab is  6433\n",
      "  (0, 5594)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 1942)\t1\n",
      "  (0, 6281)\t1\n",
      "  (1, 3080)\t1\n",
      "  (1, 5446)\t1\n",
      "  (1, 1996)\t1\n",
      "  (1, 6144)\t1\n",
      "  (1, 530)\t1\n",
      "  (1, 1905)\t1\n",
      "  (1, 4007)\t1\n",
      "  (1, 1620)\t1\n",
      "  (2, 5594)\t1\n",
      "  (2, 4007)\t1\n",
      "  (2, 5438)\t1\n",
      "  (2, 2735)\t1\n",
      "  (2, 2485)\t1\n",
      "  (2, 2683)\t1\n",
      "  (2, 2313)\t1\n",
      "  (2, 2190)\t1\n",
      "  (2, 1481)\t1\n",
      "  (2, 6088)\t1\n",
      "  (2, 5125)\t1\n",
      "  (2, 4683)\t1\n",
      "  (2, 1047)\t1\n",
      "  :\t:\n",
      "  (6, 6151)\t1\n",
      "  (7, 2735)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 4579)\t1\n",
      "  (7, 2625)\t1\n",
      "  (7, 2773)\t1\n",
      "  (7, 5145)\t1\n",
      "  (7, 2005)\t1\n",
      "  (7, 3742)\t1\n",
      "  (7, 730)\t1\n",
      "  (7, 1955)\t1\n",
      "  (7, 2824)\t2\n",
      "  (8, 5594)\t1\n",
      "  (8, 6163)\t1\n",
      "  (8, 4121)\t1\n",
      "  (8, 4561)\t1\n",
      "  (8, 3694)\t1\n",
      "  (8, 295)\t1\n",
      "  (8, 416)\t1\n",
      "  (8, 2751)\t1\n",
      "  (8, 4820)\t1\n",
      "  (8, 1948)\t1\n",
      "  (8, 4411)\t1\n",
      "  (8, 2528)\t1\n",
      "  (8, 4476)\t1\n",
      "Multinomial Naive Bayes shows a prediction accuracy of 0.732320\n"
     ]
    }
   ],
   "source": [
    "# Create a VectorizedFeature Object\n",
    "max_dfs = [.05,.07,.1,.2,.25,.3,.35,.4]\n",
    "for i in max_dfs:\n",
    "    CountVec = CountVectorizer(max_df=i)\n",
    "    FitTransformTrain = CountVec.fit_transform(train_data)\n",
    "    print 'witn max_df = ', i,' the number of word in vocab is ',FitTransformTrain.shape[1]\n",
    "    print FitTransformTrain[1:10]\n",
    "    # Try Multinomial Naive Bayes first\n",
    "    ClfMNB = MultinomialNB().fit(FitTransformTrain,train_classes)\n",
    "    # Predict Cuisine in the dev data set\n",
    "    #   Transform the dev data using the feature extractor from the train_data\n",
    "    TransformedDev = CountVec.transform(dev_data)\n",
    "    predicted = ClfMNB.predict(TransformedDev)\n",
    "    # Calculate accuracy of predictions on dev data\n",
    "    print \"Multinomial Naive Bayes shows a prediction accuracy of %f\" %(np.mean(predicted == dev_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes shows a prediction accuracy of 0.738373\n",
      "Multinomial Naive Bayes with prior norm =  100 is 0.740735272405\n",
      "Multinomial Naive Bayes with prior norm =  1000 is 0.744426398937\n",
      "Multinomial Naive Bayes with prior norm =  1500 is 0.745755204488\n",
      "Multinomial Naive Bayes with prior norm =  2000 is 0.746345784734\n",
      "Multinomial Naive Bayes with prior norm =  2500 is 0.746493429795\n",
      "Multinomial Naive Bayes with prior norm =  3000 is 0.746788719917\n"
     ]
    }
   ],
   "source": [
    "CountVec = CountVectorizer(max_df=.1)\n",
    "FitTransformTrain = CountVec.fit_transform(train_data)\n",
    "class_priors=(np.ones(num_classes))/num_classes\n",
    "ClfMNB= MultinomialNB().fit(FitTransformTrain,train_classes)\n",
    "TransformedDev = CountVec.transform(dev_data)\n",
    "predicted = ClfMNB.predict(TransformedDev)\n",
    "print \"Multinomial Naive Bayes shows a prediction accuracy of %f\" %(np.mean(predicted == dev_classes))\n",
    "\n",
    "norm_factor= [100,1000,1500,2000,2500,3000]\n",
    "for norm in norm_factor:\n",
    "    class_priors= (ClfMNB.class_count_+norm)/sum(ClfMNB.class_count_+norm)\n",
    "    ClfMNB_prior = MultinomialNB(class_prior = class_priors).fit(FitTransformTrain,train_classes)\n",
    "    predicted_prior = ClfMNB_prior.predict(TransformedDev)\n",
    "    print 'Multinomial Naive Bayes with prior norm = ', norm,'is', (np.mean(predicted_prior == dev_classes))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
